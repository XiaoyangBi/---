{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3911c483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BiXY\\anaconda3\\envs\\mmcv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#安装相关依赖库 如果是windows系统，cmd命令框中输入pip安装，或在Jupyter notebook中!pip安装，参考上述环境配置\n",
    "#!pip install pandas numpy cv2 torch torchvision time albumentations timm tqdm\n",
    "\n",
    "#---------------------------------------------------\n",
    "#导入库\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019710a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#----------------框架设置----------------\n",
    "#设置torch使用gpu\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#输出cuda说明使用gpu，输出cpu说明使用cpu，最好使用gpu训练\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae7729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------数据处理----------------\n",
    "#基础数据读取\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['path'] = 'data/train/' + train_df['image']\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('data/提交示例.csv')\n",
    "test_df['path'] = 'data/test/' + test_df['image'] \n",
    "\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, label, transforms=None):        \n",
    "        self.img_path = img_path        \n",
    "        self.label = label        \n",
    "        if transforms is not None:           \n",
    "            self.transform = transforms        \n",
    "        else:            \n",
    "            self.transform = None        \n",
    "    def __getitem__(self, index):        \n",
    "        img = cv2.imread(self.img_path[index])                    \n",
    "        img = img.astype(np.float32)                \n",
    "        img /= 255.0        \n",
    "        img -= 1                \n",
    "        \n",
    "        if self.transform is not None:            \n",
    "            img = self.transform(image = img)['image']        \n",
    "        img = img.transpose([2,0,1])                \n",
    "        \n",
    "        return img,torch.from_numpy(np.array(self.label[index]))\n",
    "    \n",
    "    def __len__(self):        \n",
    "        return len(self.img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9f73c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model----resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BiXY\\AppData\\Local\\Temp\\ipykernel_21728\\3831177988.py:89: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(X_part)\n",
      "C:\\Users\\BiXY\\AppData\\Local\\Temp\\ipykernel_21728\\3831177988.py:90: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train = y_train.append(y_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------第1折开始----------\n",
      "------epoch0----------\n",
      "-------Loss----------\n",
      "3.2128193378448486\n",
      "3.4871394634246826\n",
      "3.2597718238830566\n",
      "3.1135342121124268\n",
      "3.291262149810791\n",
      "3.157421112060547\n",
      "3.249065399169922\n",
      "loss=0.4027944167417953\n",
      "acc:0.04059729351376575\n",
      "-------Val acc----------\n",
      "loss=1.588670118690594\n",
      "acc:0.053663089127391504\n",
      "------epoch1----------\n",
      "-------Loss----------\n",
      "3.192887783050537\n",
      "3.29885196685791\n",
      "3.1287553310394287\n",
      "3.1433603763580322\n",
      "3.081665515899658\n",
      "3.1173741817474365\n",
      "3.1084694862365723\n",
      "loss=0.3949320823635612\n",
      "acc:0.06346243583761083\n",
      "-------Val acc----------\n",
      "loss=1.5518745856478677\n",
      "acc:0.09052729818012133\n",
      "------epoch2----------\n",
      "-------Loss----------\n",
      "3.1416585445404053\n",
      "3.0591979026794434\n",
      "3.1892499923706055\n",
      "3.0379488468170166\n",
      "3.154423713684082\n",
      "2.9963059425354004\n",
      "3.109548568725586\n",
      "loss=0.38752749118635826\n",
      "acc:0.08306112925804947\n",
      "-------Val acc----------\n",
      "loss=1.5165334818132892\n",
      "acc:0.13905739617358842\n",
      "------epoch3----------\n",
      "-------Loss----------\n",
      "3.042670249938965\n",
      "3.0039637088775635\n",
      "2.8975272178649902\n",
      "3.077601671218872\n",
      "3.2128188610076904\n",
      "2.878953218460083\n",
      "2.999300479888916\n",
      "loss=0.37802392057987555\n",
      "acc:0.1455902939804013\n",
      "-------Val acc----------\n",
      "loss=1.469402056456836\n",
      "acc:0.20858609426038263\n",
      "------epoch4----------\n",
      "-------Loss----------\n",
      "2.98405385017395\n",
      "3.0574519634246826\n",
      "2.8848989009857178\n",
      "3.002131223678589\n",
      "2.8269755840301514\n",
      "2.819570541381836\n",
      "2.959240674972534\n",
      "loss=0.3668716130721697\n",
      "acc:0.20671955202986467\n",
      "-------Val acc----------\n",
      "loss=1.4101103507521215\n",
      "acc:0.28931404573028463\n",
      "------epoch5----------\n",
      "-------Loss----------\n",
      "2.803058624267578\n",
      "2.8696017265319824\n",
      "2.727651596069336\n",
      "2.901404619216919\n",
      "2.8064002990722656\n",
      "2.521418333053589\n",
      "2.8339929580688477\n",
      "loss=0.352533512564947\n",
      "acc:0.2701819878674755\n",
      "-------Val acc----------\n",
      "loss=1.3292418930834273\n",
      "acc:0.3667755482967802\n",
      "------epoch6----------\n",
      "-------Loss----------\n",
      "2.757636547088623\n",
      "2.5096309185028076\n",
      "2.839871883392334\n",
      "2.9062418937683105\n",
      "2.4865922927856445\n",
      "2.5474958419799805\n",
      "2.8198084831237793\n",
      "loss=0.33564182124402664\n",
      "acc:0.3411105926271582\n",
      "-------Val acc----------\n",
      "loss=1.2555045056888225\n",
      "acc:0.4437704153056463\n",
      "------epoch7----------\n",
      "-------Loss----------\n",
      "2.419745922088623\n",
      "2.5308494567871094\n",
      "2.7151873111724854\n",
      "2.3710403442382812\n",
      "2.6524264812469482\n",
      "2.6295745372772217\n",
      "2.5700221061706543\n",
      "loss=0.3182255239393241\n",
      "acc:0.4148390107326178\n",
      "-------Val acc----------\n",
      "loss=1.175045949774149\n",
      "acc:0.5011665888940737\n",
      "------epoch8----------\n",
      "-------Loss----------\n",
      "2.4208500385284424\n",
      "2.4349470138549805\n",
      "2.507575035095215\n",
      "2.437114715576172\n",
      "2.503112554550171\n",
      "1.9774584770202637\n",
      "2.369391918182373\n",
      "loss=0.2962744416781135\n",
      "acc:0.49510032664489034\n",
      "-------Val acc----------\n",
      "loss=1.0670734972137188\n",
      "acc:0.5912272515165655\n",
      "------epoch9----------\n",
      "-------Loss----------\n",
      "2.384669303894043\n",
      "2.0611815452575684\n",
      "2.21859073638916\n",
      "2.4597280025482178\n",
      "2.3589301109313965\n",
      "2.538301944732666\n",
      "2.242401123046875\n",
      "loss=0.275967768125316\n",
      "acc:0.5408306112925805\n",
      "-------Val acc----------\n",
      "loss=0.9555726057727705\n",
      "acc:0.6444237050863276\n",
      "------epoch10----------\n",
      "-------Loss----------\n",
      "1.9752217531204224\n",
      "2.234239101409912\n",
      "2.195269823074341\n",
      "2.282306671142578\n",
      "1.9045350551605225\n",
      "2.291012763977051\n",
      "1.7846379280090332\n",
      "loss=0.2519455594656015\n",
      "acc:0.5888940737284181\n",
      "-------Val acc----------\n",
      "loss=0.8493361295910566\n",
      "acc:0.6948203453103127\n",
      "------epoch11----------\n",
      "-------Loss----------\n",
      "1.6775410175323486\n",
      "1.6027824878692627\n",
      "1.8951213359832764\n",
      "2.4186248779296875\n",
      "1.9294350147247314\n",
      "1.8195750713348389\n",
      "1.7252157926559448\n",
      "loss=0.23054390391956353\n",
      "acc:0.6332244517032198\n",
      "-------Val acc----------\n",
      "loss=0.7501189653916833\n",
      "acc:0.7270181987867476\n",
      "------epoch12----------\n",
      "-------Loss----------\n",
      "1.531724214553833\n",
      "1.5623611211776733\n",
      "1.4181327819824219\n",
      "1.6375095844268799\n",
      "1.7961323261260986\n",
      "1.367868185043335\n",
      "1.6751353740692139\n",
      "loss=0.20844073419085854\n",
      "acc:0.6836210919272049\n",
      "-------Val acc----------\n",
      "loss=0.6474522848831289\n",
      "acc:0.7755482967802146\n",
      "------epoch13----------\n",
      "-------Loss----------\n",
      "1.372617244720459\n",
      "1.6141853332519531\n",
      "1.2583403587341309\n",
      "1.237941026687622\n",
      "1.677480936050415\n",
      "1.3862437009811401\n",
      "1.3558025360107422\n",
      "loss=0.19000928584404544\n",
      "acc:0.7186187587494167\n",
      "-------Val acc----------\n",
      "loss=0.5889761921086157\n",
      "acc:0.8152123191787214\n",
      "------epoch14----------\n",
      "-------Loss----------\n",
      "1.539094090461731\n",
      "1.1733479499816895\n",
      "1.2854647636413574\n",
      "1.0526076555252075\n",
      "1.4796301126480103\n",
      "1.5794429779052734\n",
      "0.9917280077934265\n",
      "loss=0.17168260866717874\n",
      "acc:0.7494167055529631\n",
      "-------Val acc----------\n",
      "loss=0.5151843627966067\n",
      "acc:0.8427438170788614\n",
      "------epoch15----------\n",
      "-------Loss----------\n",
      "1.1474071741104126\n",
      "0.8680707216262817\n",
      "1.1286723613739014\n",
      "1.2093336582183838\n",
      "1.1258416175842285\n",
      "1.6817011833190918\n",
      "0.8619523644447327\n",
      "loss=0.15535734409602847\n",
      "acc:0.784414372375175\n",
      "-------Val acc----------\n",
      "loss=0.4702428853294864\n",
      "acc:0.8665422305179654\n",
      "------epoch16----------\n",
      "-------Loss----------\n",
      "1.274786114692688\n",
      "1.4563853740692139\n",
      "0.7904322147369385\n",
      "1.0693879127502441\n",
      "1.045139193534851\n",
      "0.9130569100379944\n",
      "1.258620023727417\n",
      "loss=0.14104782491991913\n",
      "acc:0.8058796080261316\n",
      "-------Val acc----------\n",
      "loss=0.39736510656089136\n",
      "acc:0.8777414839010733\n",
      "------epoch17----------\n",
      "-------Loss----------\n",
      "1.1308369636535645\n",
      "1.001366376876831\n",
      "1.0026923418045044\n",
      "0.8917026519775391\n",
      "0.8968485593795776\n",
      "0.7492903470993042\n",
      "0.946519672870636\n",
      "loss=0.12799847331828065\n",
      "acc:0.836677554829678\n",
      "-------Val acc----------\n",
      "loss=0.3536196874417243\n",
      "acc:0.8996733551096594\n",
      "------epoch18----------\n",
      "-------Loss----------\n",
      "1.2753082513809204\n",
      "0.6909741759300232\n",
      "0.5441999435424805\n",
      "0.905569314956665\n",
      "0.8074248433113098\n",
      "0.9533452987670898\n",
      "1.2431371212005615\n",
      "loss=0.11638442994666\n",
      "acc:0.8497433504433037\n",
      "-------Val acc----------\n",
      "loss=0.30775096961673015\n",
      "acc:0.9136724218385441\n",
      "------epoch19----------\n",
      "-------Loss----------\n",
      "0.8589690327644348\n",
      "0.8914521932601929\n",
      "1.1449998617172241\n",
      "1.1176457405090332\n",
      "1.069711446762085\n",
      "1.1728031635284424\n",
      "1.3478827476501465\n",
      "loss=0.10303393996490588\n",
      "acc:0.8679421371908539\n",
      "-------Val acc----------\n",
      "loss=0.26120295562458495\n",
      "acc:0.9225384974335045\n",
      "------epoch20----------\n",
      "-------Loss----------\n",
      "0.906221866607666\n",
      "0.7667646408081055\n",
      "0.8446075320243835\n",
      "0.7115491628646851\n",
      "0.7107623815536499\n",
      "0.6452441215515137\n",
      "0.33989807963371277\n",
      "loss=0.09487601679393859\n",
      "acc:0.8833411105926272\n",
      "-------Val acc----------\n",
      "loss=0.23405036568377433\n",
      "acc:0.9421371908539431\n",
      "------epoch21----------\n",
      "-------Loss----------\n",
      "0.7974872589111328\n",
      "0.7902326583862305\n",
      "0.5140627026557922\n",
      "0.8181167244911194\n",
      "0.6390160918235779\n",
      "0.6434295177459717\n",
      "0.6377403140068054\n",
      "loss=0.08433072436540082\n",
      "acc:0.9006066262249184\n",
      "-------Val acc----------\n",
      "loss=0.20827798117812665\n",
      "acc:0.9463369108726085\n",
      "------epoch22----------\n",
      "-------Loss----------\n",
      "0.9117828607559204\n",
      "0.6597214341163635\n",
      "0.49695679545402527\n",
      "0.5023482441902161\n",
      "0.8809350728988647\n",
      "0.4523567259311676\n",
      "0.4615321457386017\n",
      "loss=0.07855556448430477\n",
      "acc:0.9057396173588428\n",
      "-------Val acc----------\n",
      "loss=0.1735462929746653\n",
      "acc:0.9603359776014933\n",
      "------epoch23----------\n",
      "-------Loss----------\n",
      "0.6693350076675415\n",
      "0.7437622547149658\n",
      "0.8826613426208496\n",
      "0.4540579319000244\n",
      "0.24398675560951233\n",
      "0.7128726840019226\n",
      "0.45286983251571655\n",
      "loss=0.0685135103723906\n",
      "acc:0.9225384974335045\n",
      "-------Val acc----------\n",
      "loss=0.15140039347958756\n",
      "acc:0.9584694353709753\n",
      "------epoch24----------\n",
      "-------Loss----------\n",
      "0.2677616477012634\n",
      "0.3234412968158722\n",
      "0.4467718303203583\n",
      "0.4254039525985718\n",
      "0.4617474675178528\n",
      "0.3665550947189331\n",
      "0.7452590465545654\n",
      "loss=0.06418461052547032\n",
      "acc:0.9262715818945404\n",
      "-------Val acc----------\n",
      "loss=0.12712519745004758\n",
      "acc:0.9692020531964536\n",
      "------epoch25----------\n",
      "-------Loss----------\n",
      "0.5917500257492065\n",
      "0.31947776675224304\n",
      "0.45663321018218994\n",
      "0.28856873512268066\n",
      "0.41266196966171265\n",
      "0.29118287563323975\n",
      "0.3764353394508362\n",
      "loss=0.057404121483979914\n",
      "acc:0.9402706486234251\n",
      "-------Val acc----------\n",
      "loss=0.1097106267743741\n",
      "acc:0.974335044330378\n",
      "------epoch26----------\n",
      "-------Loss----------\n",
      "0.29288366436958313\n",
      "0.699310302734375\n",
      "0.6816102862358093\n",
      "0.5958656072616577\n",
      "0.3863202631473541\n",
      "0.37493303418159485\n",
      "0.29584529995918274\n",
      "loss=0.051091220589703175\n",
      "acc:0.9491367242183855\n",
      "-------Val acc----------\n",
      "loss=0.08953010043134975\n",
      "acc:0.9790013999066729\n",
      "------epoch27----------\n",
      "-------Loss----------\n",
      "0.26084965467453003\n",
      "0.2672732174396515\n",
      "0.30553755164146423\n",
      "0.23036028444766998\n",
      "0.4063704013824463\n",
      "0.1748649626970291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5044633150100708\n",
      "loss=0.04561069490222023\n",
      "acc:0.9510032664489034\n",
      "-------Val acc----------\n",
      "loss=0.08364539245309545\n",
      "acc:0.9813345776948204\n",
      "------epoch28----------\n",
      "-------Loss----------\n",
      "1.0055181980133057\n",
      "0.4926382899284363\n",
      "0.33326879143714905\n",
      "0.12292416393756866\n",
      "0.2014501690864563\n",
      "0.4953933358192444\n",
      "0.28559887409210205\n",
      "loss=0.04249355188956396\n",
      "acc:0.9570695286980868\n",
      "-------Val acc----------\n",
      "loss=0.06758987846164136\n",
      "acc:0.9874008399440037\n",
      "------epoch29----------\n",
      "-------Loss----------\n",
      "0.31538334488868713\n",
      "0.11974281072616577\n",
      "0.18956351280212402\n",
      "0.40988004207611084\n",
      "0.14714786410331726\n",
      "0.2538199722766876\n",
      "0.8177523016929626\n",
      "loss=0.03728694731227939\n",
      "acc:0.9640690620625292\n",
      "-------Val acc----------\n",
      "loss=0.0603835365688928\n",
      "acc:0.9874008399440037\n",
      "------epoch30----------\n",
      "-------Loss----------\n",
      "0.2919595241546631\n",
      "0.17064765095710754\n",
      "0.2329668551683426\n",
      "0.2151106894016266\n",
      "0.10552483052015305\n",
      "0.16132639348506927\n",
      "0.09508809447288513\n",
      "loss=0.033063524858561066\n",
      "acc:0.9738684087727485\n",
      "-------Val acc----------\n",
      "loss=0.04763006171727891\n",
      "acc:0.9916005599626692\n",
      "------epoch31----------\n",
      "-------Loss----------\n",
      "0.1586909294128418\n",
      "0.27752360701560974\n",
      "0.1667531579732895\n",
      "0.2151116132736206\n",
      "0.23030531406402588\n",
      "0.2139737904071808\n",
      "0.18707214295864105\n",
      "loss=0.02995943272859206\n",
      "acc:0.9757349510032665\n",
      "-------Val acc----------\n",
      "loss=0.04019237443656112\n",
      "acc:0.9925338310779281\n",
      "------epoch32----------\n",
      "-------Loss----------\n",
      "0.2309255301952362\n",
      "0.10007965564727783\n",
      "0.1635740101337433\n",
      "0.044720496982336044\n",
      "0.1576347053050995\n",
      "0.20293593406677246\n",
      "0.14826536178588867\n",
      "loss=0.02660147081043639\n",
      "acc:0.9776014932337844\n",
      "-------Val acc----------\n",
      "loss=0.0388791568067083\n",
      "acc:0.9939337377508166\n",
      "------epoch33----------\n",
      "-------Loss----------\n",
      "0.08495433628559113\n",
      "0.07120787352323532\n",
      "0.3603649139404297\n",
      "0.2754919230937958\n",
      "0.2633717358112335\n",
      "0.0736156553030014\n",
      "0.41850006580352783\n",
      "loss=0.025197340626612035\n",
      "acc:0.9776014932337844\n",
      "-------Val acc----------\n",
      "loss=0.03063111032854298\n",
      "acc:0.9939337377508166\n",
      "------epoch34----------\n",
      "-------Loss----------\n",
      "0.252792626619339\n",
      "0.21457697451114655\n",
      "0.14184369146823883\n",
      "0.12812075018882751\n",
      "0.16585852205753326\n",
      "0.0684751570224762\n",
      "0.05502180755138397\n",
      "loss=0.022069109987069443\n",
      "acc:0.9874008399440037\n",
      "-------Val acc----------\n",
      "loss=0.025928951313999898\n",
      "acc:0.9948670088660756\n",
      "第1折交叉验证train_loss=0.17047070107311574,train_acc=0.6946336910872608,val_loss=0.5699657144084784,val_acc=0.751909872675155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 510/510 [00:24<00:00, 20.95it/s]\n",
      "C:\\Users\\BiXY\\AppData\\Local\\Temp\\ipykernel_21728\\3831177988.py:90: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train = y_train.append(y_part)\n",
      "C:\\Users\\BiXY\\AppData\\Local\\Temp\\ipykernel_21728\\3831177988.py:89: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(X_part)\n",
      "C:\\Users\\BiXY\\AppData\\Local\\Temp\\ipykernel_21728\\3831177988.py:90: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train = y_train.append(y_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------第2折开始----------\n",
      "------epoch0----------\n",
      "-------Loss----------\n",
      "3.4102354049682617\n",
      "3.242680072784424\n",
      "3.272956132888794\n",
      "3.3755722045898438\n",
      "2.986555814743042\n",
      "3.353910446166992\n",
      "3.0813965797424316\n",
      "loss=0.4033193574906285\n",
      "acc:0.046196920205319646\n",
      "-------Val acc----------\n",
      "loss=1.5872284109994066\n",
      "acc:0.06672888474101726\n",
      "------epoch1----------\n",
      "-------Loss----------\n",
      "3.1463685035705566\n",
      "3.242741823196411\n",
      "3.12009596824646\n",
      "3.1986587047576904\n",
      "3.074615478515625\n",
      "3.215426445007324\n",
      "3.0304512977600098\n",
      "loss=0.3945593642565451\n",
      "acc:0.07419505366308912\n",
      "-------Val acc----------\n",
      "loss=1.5496279647068838\n",
      "acc:0.10312645823611759\n",
      "------epoch2----------\n",
      "-------Loss----------\n",
      "3.022829294204712\n",
      "3.0645954608917236\n",
      "2.9798266887664795\n",
      "3.098111391067505\n",
      "3.078979730606079\n",
      "3.014927625656128\n",
      "3.3430047035217285\n",
      "loss=0.3854448413715372\n",
      "acc:0.11245916938870743\n",
      "-------Val acc----------\n",
      "loss=1.5053315368479676\n",
      "acc:0.15212319178721417\n",
      "------epoch3----------\n",
      "-------Loss----------\n",
      "2.9520039558410645\n",
      "2.982607841491699\n",
      "3.0618739128112793\n",
      "3.0167198181152344\n",
      "2.8643569946289062\n",
      "2.8764803409576416\n",
      "2.8664119243621826\n",
      "loss=0.3741352568148899\n",
      "acc:0.15632291180587962\n",
      "-------Val acc----------\n",
      "loss=1.4443722904924472\n",
      "acc:0.20718618758749416\n",
      "------epoch4----------\n",
      "-------Loss----------\n",
      "2.871669292449951\n",
      "2.9746482372283936\n",
      "2.9023163318634033\n",
      "3.1136302947998047\n",
      "2.793309450149536\n",
      "2.9375791549682617\n",
      "2.868565320968628\n",
      "loss=0.36010318085015847\n",
      "acc:0.21231917872141856\n",
      "-------Val acc----------\n",
      "loss=1.3768413407303048\n",
      "acc:0.2809146056929538\n",
      "------epoch5----------\n",
      "-------Loss----------\n",
      "3.0892224311828613\n",
      "2.824516773223877\n",
      "2.823855400085449\n",
      "3.094329833984375\n",
      "2.71494722366333\n",
      "2.7619900703430176\n",
      "2.8074474334716797\n",
      "loss=0.3431655932296062\n",
      "acc:0.27858142790480633\n",
      "-------Val acc----------\n",
      "loss=1.2843726890642289\n",
      "acc:0.33877741483901075\n",
      "------epoch6----------\n",
      "-------Loss----------\n",
      "2.6755149364471436\n",
      "2.516221046447754\n",
      "2.3641223907470703\n",
      "2.667564868927002\n",
      "2.5606577396392822\n",
      "2.6348235607147217\n",
      "2.295657157897949\n",
      "loss=0.3244320465146633\n",
      "acc:0.3117125524965002\n",
      "-------Val acc----------\n",
      "loss=1.194767321235267\n",
      "acc:0.43303779748016796\n",
      "------epoch7----------\n",
      "-------Loss----------\n",
      "2.2429356575012207\n",
      "2.4178571701049805\n",
      "2.1956357955932617\n",
      "2.3244576454162598\n",
      "2.470198631286621\n",
      "2.5687057971954346\n",
      "2.6011033058166504\n",
      "loss=0.30246880179079016\n",
      "acc:0.40223985067662155\n",
      "-------Val acc----------\n",
      "loss=1.0865661120559365\n",
      "acc:0.511899206719552\n",
      "------epoch8----------\n",
      "-------Loss----------\n",
      "2.158341646194458\n",
      "2.2710325717926025\n",
      "2.0626018047332764\n",
      "2.2791385650634766\n",
      "2.416614055633545\n",
      "2.4678807258605957\n",
      "1.9872310161590576\n",
      "loss=0.28174327468961075\n",
      "acc:0.4671021931871209\n",
      "-------Val acc----------\n",
      "loss=0.9804453024561585\n",
      "acc:0.5846943537097526\n",
      "------epoch9----------\n",
      "-------Loss----------\n",
      "2.09688401222229\n",
      "2.219011068344116\n",
      "1.9426679611206055\n",
      "2.019784450531006\n",
      "2.0125718116760254\n",
      "1.880834698677063\n",
      "2.1571733951568604\n",
      "loss=0.2573802363800213\n",
      "acc:0.5408306112925805\n",
      "-------Val acc----------\n",
      "loss=0.8842175719313015\n",
      "acc:0.653289780681288\n",
      "------epoch10----------\n",
      "-------Loss----------\n",
      "1.8783149719238281\n",
      "2.103828191757202\n",
      "2.2384936809539795\n",
      "2.0681004524230957\n",
      "1.8270188570022583\n",
      "2.3128538131713867\n",
      "1.6979162693023682\n",
      "loss=0.2378814733312111\n",
      "acc:0.5982267848810079\n",
      "-------Val acc----------\n",
      "loss=0.8106334573383706\n",
      "acc:0.6868875408306113\n",
      "------epoch11----------\n",
      "-------Loss----------\n",
      "2.048809766769409\n",
      "1.9571293592453003\n",
      "1.400443434715271\n",
      "1.8337401151657104\n",
      "1.8328417539596558\n",
      "1.7162561416625977\n",
      "1.8241153955459595\n",
      "loss=0.21509033833715996\n",
      "acc:0.653289780681288\n",
      "-------Val acc----------\n",
      "loss=0.7113179703683314\n",
      "acc:0.7209519365375642\n",
      "------epoch12----------\n",
      "-------Loss----------\n",
      "1.6742002964019775\n",
      "1.5205092430114746\n",
      "1.5427664518356323\n",
      "1.7829383611679077\n",
      "1.618891716003418\n",
      "1.2549341917037964\n",
      "1.8422644138336182\n",
      "loss=0.1989455505670146\n",
      "acc:0.6878208119458703\n",
      "-------Val acc----------\n",
      "loss=0.6378302522737236\n",
      "acc:0.7750816612225851\n",
      "------epoch13----------\n",
      "-------Loss----------\n",
      "1.469969391822815\n",
      "1.8892852067947388\n",
      "1.5565959215164185\n",
      "1.4518934488296509\n",
      "1.3160293102264404\n",
      "1.8588833808898926\n",
      "1.2260240316390991\n",
      "loss=0.18290134022517343\n",
      "acc:0.7246850209986001\n",
      "-------Val acc----------\n",
      "loss=0.5664637885462777\n",
      "acc:0.809146056929538\n",
      "------epoch14----------\n",
      "-------Loss----------\n",
      "1.0759961605072021\n",
      "1.441615343093872\n",
      "0.9779402017593384\n",
      "1.3257966041564941\n",
      "1.6865551471710205\n",
      "1.1132569313049316\n",
      "0.8150522112846375\n",
      "loss=0.16673763845214987\n",
      "acc:0.7554829678021465\n",
      "-------Val acc----------\n",
      "loss=0.4983865969992107\n",
      "acc:0.8306112925804946\n",
      "------epoch15----------\n",
      "-------Loss----------\n",
      "0.9588800668716431\n",
      "1.0800014734268188\n",
      "1.1255223751068115\n",
      "1.190605640411377\n",
      "1.2192730903625488\n",
      "1.1768176555633545\n",
      "0.7541971206665039\n",
      "loss=0.14843018061637434\n",
      "acc:0.7792813812412506\n",
      "-------Val acc----------\n",
      "loss=0.4325121117289023\n",
      "acc:0.8600093327111525\n",
      "------epoch16----------\n",
      "-------Loss----------\n",
      "1.2567230463027954\n",
      "1.1746833324432373\n",
      "1.0948997735977173\n",
      "0.9909968376159668\n",
      "1.052909255027771\n",
      "0.8821156620979309\n",
      "1.1803184747695923\n",
      "loss=0.13788198520800135\n",
      "acc:0.8147456836210919\n",
      "-------Val acc----------\n",
      "loss=0.3900324124364835\n",
      "acc:0.8842743817078862\n",
      "------epoch17----------\n",
      "-------Loss----------\n",
      "1.833742618560791\n",
      "0.9359506368637085\n",
      "1.0624010562896729\n",
      "1.0800213813781738\n",
      "0.918616533279419\n",
      "0.8542959094047546\n",
      "0.9148382544517517\n",
      "loss=0.12517067653744565\n",
      "acc:0.8287447503499766\n",
      "-------Val acc----------\n",
      "loss=0.32855830637792866\n",
      "acc:0.8959402706486235\n",
      "------epoch18----------\n",
      "-------Loss----------\n",
      "0.7085588574409485\n",
      "1.4086681604385376\n",
      "0.8071207404136658\n",
      "0.8513591289520264\n",
      "1.4096561670303345\n",
      "1.2509164810180664\n",
      "1.2499786615371704\n",
      "loss=0.11284791430301105\n",
      "acc:0.8483434437704153\n",
      "-------Val acc----------\n",
      "loss=0.29597464128390016\n",
      "acc:0.9127391507232852\n",
      "------epoch19----------\n",
      "-------Loss----------\n",
      "1.4810632467269897\n",
      "1.0979230403900146\n",
      "0.8394335508346558\n",
      "0.6115133762359619\n",
      "0.6471847295761108\n",
      "0.3535121977329254\n",
      "0.788608729839325\n",
      "loss=0.10301372450587352\n",
      "acc:0.8698086794213719\n",
      "-------Val acc----------\n",
      "loss=0.2612777553660412\n",
      "acc:0.922071861875875\n",
      "------epoch20----------\n",
      "-------Loss----------\n",
      "1.0575050115585327\n",
      "0.7594519853591919\n",
      "0.7510408759117126\n",
      "0.5262259244918823\n",
      "0.9325511455535889\n",
      "0.44852569699287415\n",
      "0.9483397603034973\n",
      "loss=0.0926829553546051\n",
      "acc:0.8786747550163323\n",
      "-------Val acc----------\n",
      "loss=0.2236006625615516\n",
      "acc:0.9416705552963136\n",
      "------epoch21----------\n",
      "-------Loss----------\n",
      "0.3696433901786804\n",
      "0.5513050556182861\n",
      "0.5005811452865601\n",
      "0.5604616403579712\n",
      "1.0324854850769043\n",
      "0.9900417327880859\n",
      "0.749047040939331\n",
      "loss=0.08694737044050489\n",
      "acc:0.8940737284181055\n",
      "-------Val acc----------\n",
      "loss=0.19696246058694458\n",
      "acc:0.945870275314979\n",
      "------epoch22----------\n",
      "-------Loss----------\n",
      "0.8417251110076904\n",
      "0.5249160528182983\n",
      "0.33552104234695435\n",
      "0.6061702370643616\n",
      "0.8925585746765137\n",
      "0.7281454205513\n",
      "0.556707501411438\n",
      "loss=0.07500614133384036\n",
      "acc:0.9118058796080262\n",
      "-------Val acc----------\n",
      "loss=0.15899245213452992\n",
      "acc:0.9608026131591227\n",
      "------epoch23----------\n",
      "-------Loss----------\n",
      "0.9791536927223206\n",
      "0.329208642244339\n",
      "0.5049898624420166\n",
      "0.6269688010215759\n",
      "0.7188334465026855\n",
      "0.6338286399841309\n",
      "0.8822804093360901\n",
      "loss=0.06729747939070863\n",
      "acc:0.9300046663555763\n",
      "-------Val acc----------\n",
      "loss=0.14075543023767562\n",
      "acc:0.9664022398506766\n",
      "------epoch24----------\n",
      "-------Loss----------\n",
      "0.5295116305351257\n",
      "0.5732932090759277\n",
      "0.4864006042480469\n",
      "0.5684904456138611\n",
      "0.4458329379558563\n",
      "0.15782108902931213\n",
      "0.3920867443084717\n",
      "loss=0.06058793970067758\n",
      "acc:0.9379374708352777\n",
      "-------Val acc----------\n",
      "loss=0.11941212346161074\n",
      "acc:0.9701353243117126\n",
      "------epoch25----------\n",
      "-------Loss----------\n",
      "0.3023337423801422\n",
      "0.1879361867904663\n",
      "0.27870050072669983\n",
      "0.3898065686225891\n",
      "0.402233362197876\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms       \n",
    "#----------------模型训练----------------\n",
    "       \n",
    "# 模型训练一个epoch的函数\n",
    "def train(train_loader, model, criterion, optimizer):   \n",
    "    model.train()  \n",
    "    train_acc = 0.0  \n",
    "    train_loss = 0.0    \n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):               \n",
    "        input = input.to(device)        \n",
    "        target = target.to(device)        \n",
    "        output = model(input)      \n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i % 40 == 0:            \n",
    "            print(loss.item())\n",
    "        train_acc += (output.argmax(1) == target).sum().item()                             \n",
    "        train_loss += loss.item()        \n",
    "    \n",
    "    return train_loss/len(train_loader.dataset),train_acc / len(train_loader.dataset)\n",
    "\n",
    "# 模型验证一个epoch的函数\n",
    "# 模型验证一个epoch的函数\n",
    "def validate(val_loader, model, criterion):    \n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0        \n",
    "    \n",
    "    with torch.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(val_loader):  \n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)            \n",
    "            val_loss += criterion(output, target).item()\n",
    "            val_acc += (output.argmax(1) == target).sum().item()                   \n",
    "        return val_loss/len(val_loader.dataset),val_acc / len(val_loader.dataset)    \n",
    "    \n",
    "# 模型预测函数     \n",
    "def predict(test_loader, model, criterion):    \n",
    "    model.eval()    \n",
    "    val_acc = 0.0        \n",
    "    \n",
    "    test_pred = []    \n",
    "    with torch.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(test_loader):    \n",
    "            input = input.to(device)            \n",
    "            target = target.to(device)            \n",
    "            output = model(input)            \n",
    "            test_pred.append(output.data.cpu().numpy())                \n",
    "            return np.vstack(test_pred)\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        # 此处的self.smoothing即我们的epsilon平滑参数。\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = X_train.append(X_part)\n",
    "            y_train = y_train.append(y_part)\n",
    "    train_loader = torch.utils.data.DataLoader(    \n",
    "        XunFeiDataset(train_df['path'].values, train_df['label'].values,           \n",
    "        A.Compose([            \n",
    "            A.RandomCrop(450, 750),\n",
    "            A.CoarseDropout(p=0.5)\n",
    "            ])\n",
    "            ), batch_size=8, shuffle=True, num_workers=0, pin_memory=False)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(    \n",
    "        XunFeiDataset(train_df['path'].values, train_df['label'].values,            \n",
    "        A.Compose([            \n",
    "            A.RandomCrop(450, 750), \n",
    "            A.CoarseDropout(p=0.5)\n",
    "            ])    \n",
    "            ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False)    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "result = pd.DataFrame()\n",
    "# 定义模型，使用resnet18\n",
    "print(\"Creating model----{}\".format('resnet34'))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.0001\n",
    "n_epochs = 3\n",
    "k_fold = 5\n",
    "for i in range(k_fold):\n",
    "    train_loss_mean = 0.0\n",
    "    train_acc_mean = 0.0\n",
    "    val_loss_mean = 0.0\n",
    "    val_acc_mean = 0.0\n",
    "\n",
    "    train_loader,val_loader = get_k_fold_data(k_fold, i, train_df['path'], train_df['label'])\n",
    "    model = timm.create_model('resnet34', pretrained=True, num_classes=24)  # 通过修改模型名字更换不同模型  \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                              max_lr=lr, \n",
    "                                              steps_per_epoch=int(len(train_loader)),\n",
    "                                              epochs=n_epochs,\n",
    "                                              anneal_strategy='cos')\n",
    "    print(\"---------第{}折开始----------\".format(i+1))\n",
    "    epochs = 35\n",
    "    for epoch in range(epochs):\n",
    "        print(\"------epoch{}----------\".format(epoch))   \n",
    "        print(\"-------Loss----------\")      \n",
    "        train_loss,train_acc = train(train_loader, model, criterion, optimizer) \n",
    "        train_loss_mean += train_loss/epochs\n",
    "        train_acc_mean += train_acc/epochs\n",
    "        print(\"loss={}\".format(train_loss))  \n",
    "        print(\"acc:{}\".format(train_acc)) \n",
    "\n",
    "        print(\"-------Val acc----------\") \n",
    "        val_loss, val_acc = validate(val_loader, model, criterion) \n",
    "        val_loss_mean += val_loss/epochs\n",
    "        val_acc_mean += val_acc/epochs \n",
    "        print(\"loss={}\".format(val_loss))  \n",
    "        print(\"acc:{}\".format(val_acc)) \n",
    "    print(\"第{}折交叉验证train_loss={},train_acc={},val_loss={},val_acc={}\".format(i+1,train_loss_mean,train_acc_mean,val_loss_mean,val_acc_mean))\n",
    "    scheduler.step()\n",
    "#----------------模型测试----------------\n",
    "#1. result为每一折测试集预测得到五组种类组合成的Dataframe\n",
    "#2. pred为每一折测试集得到的原始结果相加\n",
    "    # 模型预测\n",
    "    test_loader = torch.utils.data.DataLoader(    \n",
    "        XunFeiDataset(test_df['path'].values, [0] * test_df.shape[0],            \n",
    "            A.Compose([            \n",
    "                A.RandomCrop(450, 750), \n",
    "                ])    \n",
    "                ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "    model.eval()    \n",
    "    val_acc = 0.0        \n",
    "\n",
    "\n",
    "    test_pred = []    \n",
    "    with torch.no_grad():  \n",
    "        for input, _ in tqdm(test_loader):\n",
    "            # print(img[0])\n",
    "            input = input.to(device)                      \n",
    "            output = model(input)            \n",
    "            test_pred.append(output.data.cpu().numpy())                \n",
    "\n",
    "    pred = np.vstack(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a714820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()    \n",
    "val_acc = 0.0        \n",
    "\n",
    "\n",
    "test_pred = []    \n",
    "with torch.no_grad():  \n",
    "    for input, _ in tqdm(test_loader):\n",
    "        # print(img[0])\n",
    "        input = input.to(device)                      \n",
    "        output = model(input)            \n",
    "        test_pred.append(output.data.cpu().numpy())                \n",
    "\n",
    "pred = np.vstack(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fde4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#保存五次预测投票后的结果\n",
    "label = np.array(result.mode(1)[0],dtype=int)\n",
    "print(pred.argmax(1))\n",
    "print([x.split('/')[-1] for x in test_df['path'].values])\n",
    "# pd.DataFrame(    \n",
    "#     {        \n",
    "#         'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "#         'label': label \n",
    "#         }).to_csv('result.csv', index=None)\n",
    "        \n",
    "# #保存五次预测的原始结果(1020*24)求和后每一个样本的最大分数对应的类\n",
    "# pd.DataFrame(    \n",
    "#     {        \n",
    "#         'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "#         'label': pred.argmax(1)\n",
    "#         }).to_csv('result2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23906df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
