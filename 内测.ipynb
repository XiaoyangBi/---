{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703426d2",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0b287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BiXY\\anaconda3\\envs\\mmcv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#安装相关依赖库 如果是windows系统，cmd命令框中输入pip安装，或在Jupyter notebook中!pip安装，参考上述环境配置\n",
    "#!pip install pandas numpy cv2 torch torchvision time albumentations timm tqdm\n",
    "\n",
    "#---------------------------------------------------\n",
    "#导入库\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import models\n",
    "from torchvision.datasets import DatasetFolder\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab66205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce393e2",
   "metadata": {},
   "source": [
    "# 框架设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac74772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#----------------框架设置----------------\n",
    "#设置torch使用gpu\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#输出cuda说明使用gpu，输出cpu说明使用cpu，最好使用gpu训练\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddd2be",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159fcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------数据处理----------------\n",
    "#基础数据读取\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['path'] = 'data/train/' + train_df['image']\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('data/提交示例.csv')\n",
    "test_df['path'] = 'data/test/' + test_df['image'] \n",
    "\n",
    "# 定义数据集读取方法\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, label, transform=None):        \n",
    "        self.img_path = img_path        \n",
    "        self.label = label        \n",
    "        if transform is not None:           \n",
    "            self.transform = transform        \n",
    "        else:            \n",
    "            self.transform = None        \n",
    "    def __getitem__(self, index):        \n",
    "        img = cv2.imread(self.img_path[index])                    \n",
    "        img = img.astype(np.float32)                \n",
    "        img /= 255.0        \n",
    "        img -= 1                \n",
    "        \n",
    "        if self.transform is not None:            \n",
    "            img = self.transform(image = img)['image']        \n",
    "        img = img.transpose([2,0,1])                \n",
    "        \n",
    "        return img,torch.from_numpy(np.array(self.label[index]))        \n",
    "    \n",
    "    def __len__(self):        \n",
    "        return len(self.img_path)\n",
    "   \n",
    "   \n",
    "#使用torch批量数据读取\n",
    "train_loader = torch.utils.data.DataLoader(    \n",
    "    XunFeiDataset(train_df['path'].values, train_df['label'].values,           \n",
    "    A.Compose([            \n",
    "        A.RandomCrop(450, 750),\n",
    "        A.CoarseDropout(p=0.5)\n",
    "        ])\n",
    "        ), batch_size=8, shuffle=True, num_workers=0, pin_memory=False)\n",
    "    \n",
    "val_loader = torch.utils.data.DataLoader(    \n",
    "    XunFeiDataset(train_df['path'].values[:-200], train_df['label'].values[:-200],            \n",
    "    A.Compose([            \n",
    "        A.RandomCrop(450, 750), \n",
    "        A.CoarseDropout(p=0.5)\n",
    "        ])    \n",
    "        ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f466e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler():\n",
    "    \"\"\"\n",
    "    Learning rate scheduler. If the validation loss does not decrease for the\n",
    "    given number of `patience` epochs, then the learning rate will decrease by\n",
    "    by given `factor`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, optimizer, patience=5, min_lr=1e-6, factor=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        new_lr = old_lr * factor\n",
    "        :param optimizer: the optimizer we are using\n",
    "        :param patience: how many epochs to wait before updating the lr\n",
    "        :param min_lr: least lr value to reduce to while updating\n",
    "        :param factor: factor by which the lr should be updated\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                mode='min',\n",
    "                patience=self.patience,\n",
    "                factor=self.factor,\n",
    "                min_lr=self.min_lr,\n",
    "                verbose=True\n",
    "            )\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)\n",
    "\n",
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502f392",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a483dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model----resnet18d\n",
      "------epoch0----------\n",
      "-------Loss----------\n",
      "3.127227783203125\n",
      "3.1971163749694824\n",
      "3.153848886489868\n",
      "3.159370183944702\n",
      "3.1751434803009033\n",
      "2.9723458290100098\n",
      "2.9698309898376465\n",
      "3.1253415639720745\n",
      "-------Val acc----------\n",
      "0.27380339680905813\n",
      "------epoch1----------\n",
      "-------Loss----------\n",
      "2.791243553161621\n",
      "2.9250807762145996\n",
      "2.6188745498657227\n",
      "2.701113700866699\n",
      "2.3806347846984863\n",
      "2.249156951904297\n",
      "2.282310724258423\n",
      "2.5663539971878278\n",
      "-------Val acc----------\n",
      "0.7344312918167781\n",
      "------epoch2----------\n",
      "-------Loss----------\n",
      "2.3944058418273926\n",
      "2.4326140880584717\n",
      "2.3966429233551025\n",
      "1.9910833835601807\n",
      "2.175626754760742\n",
      "2.183783769607544\n",
      "1.935177206993103\n",
      "2.099251750245023\n",
      "-------Val acc----------\n",
      "0.9047864127637674\n",
      "------epoch3----------\n",
      "-------Loss----------\n",
      "1.8523657321929932\n",
      "1.8172318935394287\n",
      "1.8241829872131348\n",
      "1.96187424659729\n",
      "1.9777195453643799\n",
      "1.8914158344268799\n",
      "1.9881277084350586\n",
      "1.892679771380638\n",
      "-------Val acc----------\n",
      "0.9397838394235718\n",
      "------epoch4----------\n",
      "-------Loss----------\n",
      "1.973405361175537\n",
      "1.9311962127685547\n",
      "1.6882011890411377\n",
      "1.7051771879196167\n",
      "1.6677567958831787\n",
      "1.654432773590088\n",
      "1.6179745197296143\n",
      "1.7682530715394376\n",
      "-------Val acc----------\n",
      "0.9644879053010808\n",
      "------epoch5----------\n",
      "-------Loss----------\n",
      "1.6270169019699097\n",
      "1.6305009126663208\n",
      "1.903817057609558\n",
      "1.9384629726409912\n",
      "1.627487063407898\n",
      "1.6330690383911133\n",
      "1.6111869812011719\n",
      "1.705287832377562\n",
      "-------Val acc----------\n",
      "0.9835306227483274\n",
      "------epoch6----------\n",
      "-------Loss----------\n",
      "1.8013337850570679\n",
      "1.5736541748046875\n",
      "1.619209885597229\n",
      "1.672620415687561\n",
      "1.584093689918518\n",
      "1.6909087896347046\n",
      "1.772944688796997\n",
      "1.6583703351554586\n",
      "-------Val acc----------\n",
      "0.9927946474523932\n",
      "------epoch7----------\n",
      "-------Loss----------\n",
      "1.5882943868637085\n",
      "1.6304054260253906\n",
      "1.6008808612823486\n",
      "1.6674985885620117\n",
      "1.6050300598144531\n",
      "1.617264986038208\n",
      "1.697710394859314\n",
      "1.6229720822910765\n",
      "-------Val acc----------\n",
      "0.9969119917653114\n",
      "------epoch8----------\n",
      "-------Loss----------\n",
      "1.5722407102584839\n",
      "1.5905959606170654\n",
      "1.5547189712524414\n",
      "1.6194052696228027\n",
      "1.598747730255127\n",
      "1.5735831260681152\n",
      "1.5961506366729736\n",
      "1.602636905303642\n",
      "-------Val acc----------\n",
      "0.9948533196088523\n",
      "------epoch9----------\n",
      "-------Loss----------\n",
      "1.5666029453277588\n",
      "1.6084264516830444\n",
      "1.6456265449523926\n",
      "1.577331304550171\n",
      "1.5907392501831055\n",
      "1.622483491897583\n",
      "1.55458402633667\n",
      "1.589250911972416\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 1 of 5\n",
      "0.9969119917653114\n",
      "------epoch10----------\n",
      "-------Loss----------\n",
      "1.5670877695083618\n",
      "1.6407533884048462\n",
      "1.5528371334075928\n",
      "1.5957088470458984\n",
      "1.594184398651123\n",
      "1.622886300086975\n",
      "1.5911861658096313\n",
      "1.5824183488070076\n",
      "-------Val acc----------\n",
      "0.9989706639217705\n",
      "------epoch11----------\n",
      "-------Loss----------\n",
      "1.7599589824676514\n",
      "1.5573903322219849\n",
      "1.532213568687439\n",
      "1.711517095565796\n",
      "1.530953049659729\n",
      "1.5438413619995117\n",
      "1.594814419746399\n",
      "1.5715149783376436\n",
      "-------Val acc----------\n",
      "0.9989706639217705\n",
      "------epoch12----------\n",
      "-------Loss----------\n",
      "1.5595488548278809\n",
      "1.528872013092041\n",
      "1.5504968166351318\n",
      "1.546743631362915\n",
      "1.5328810214996338\n",
      "1.5848236083984375\n",
      "1.55751633644104\n",
      "1.5630646512579562\n",
      "-------Val acc----------\n",
      "0.9989706639217705\n",
      "------epoch13----------\n",
      "-------Loss----------\n",
      "1.530487298965454\n",
      "1.5325958728790283\n",
      "1.5559611320495605\n",
      "1.5397242307662964\n",
      "1.5475406646728516\n",
      "1.5301947593688965\n",
      "1.5334820747375488\n",
      "1.5571824507926828\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 1 of 5\n",
      "0.9994853319608852\n",
      "------epoch14----------\n",
      "-------Loss----------\n",
      "1.56172776222229\n",
      "1.5393521785736084\n",
      "1.5290377140045166\n",
      "1.5315706729888916\n",
      "1.5383708477020264\n",
      "1.5409051179885864\n",
      "1.5286445617675781\n",
      "1.5494626587006584\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n",
      "------epoch15----------\n",
      "-------Loss----------\n",
      "1.5754045248031616\n",
      "1.5387492179870605\n",
      "1.5378801822662354\n",
      "1.5230870246887207\n",
      "1.533564805984497\n",
      "1.5343167781829834\n",
      "1.5281859636306763\n",
      "1.5448159642183958\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n",
      "------epoch16----------\n",
      "-------Loss----------\n",
      "1.5311686992645264\n",
      "1.543210744857788\n",
      "1.5580387115478516\n",
      "1.5615990161895752\n",
      "1.5368175506591797\n",
      "1.5414258241653442\n",
      "1.5652880668640137\n",
      "1.5429297734552354\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 1 of 5\n",
      "0.9989706639217705\n",
      "------epoch17----------\n",
      "-------Loss----------\n",
      "1.5377418994903564\n",
      "1.5170350074768066\n",
      "1.5418457984924316\n",
      "1.5422718524932861\n",
      "1.5232794284820557\n",
      "1.558490514755249\n",
      "1.5391926765441895\n",
      "1.5376255641232675\n",
      "-------Val acc----------\n",
      "0.9989706639217705\n",
      "------epoch18----------\n",
      "-------Loss----------\n",
      "1.5229971408843994\n",
      "1.520411491394043\n",
      "1.5419535636901855\n",
      "1.5242671966552734\n",
      "1.5392743349075317\n",
      "1.544102668762207\n",
      "1.525039553642273\n",
      "1.538542364960286\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 1 of 5\n",
      "0.9994853319608852\n",
      "------epoch19----------\n",
      "-------Loss----------\n",
      "1.53985595703125\n",
      "1.545093297958374\n",
      "1.5563313961029053\n",
      "1.5472724437713623\n",
      "1.5300734043121338\n",
      "1.527969241142273\n",
      "1.5453088283538818\n",
      "1.5383649922128935\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n",
      "------epoch20----------\n",
      "-------Loss----------\n",
      "1.526121735572815\n",
      "1.5304758548736572\n",
      "1.5453317165374756\n",
      "1.5199167728424072\n",
      "1.5418097972869873\n",
      "1.5423113107681274\n",
      "1.524338722229004\n",
      "1.5343145158753466\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 1 of 5\n",
      "0.9974266598044261\n",
      "------epoch21----------\n",
      "-------Loss----------\n",
      "1.5167045593261719\n",
      "1.5489848852157593\n",
      "1.5282301902770996\n",
      "1.5245163440704346\n",
      "1.5397676229476929\n",
      "1.5309735536575317\n",
      "1.5193545818328857\n",
      "1.533159144333939\n",
      "-------Val acc----------\n",
      "INFO: Early stopping counter 2 of 5\n",
      "0.9994853319608852\n",
      "------epoch22----------\n",
      "-------Loss----------\n",
      "1.5372533798217773\n",
      "1.5493592023849487\n",
      "1.5190492868423462\n",
      "1.51908540725708\n",
      "1.5273404121398926\n",
      "1.526702642440796\n",
      "1.5197302103042603\n",
      "1.5330279322702494\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n",
      "------epoch23----------\n",
      "-------Loss----------\n",
      "1.5433740615844727\n",
      "1.533618450164795\n",
      "1.5916002988815308\n",
      "1.569405198097229\n",
      "1.5213615894317627\n",
      "1.5579376220703125\n",
      "1.5339082479476929\n",
      "1.5394074988009325\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n",
      "------epoch24----------\n",
      "-------Loss----------\n",
      "1.5190459489822388\n",
      "1.5388214588165283\n",
      "1.565900444984436\n",
      "1.5254640579223633\n",
      "1.5218336582183838\n",
      "1.5254542827606201\n",
      "1.527420997619629\n",
      "1.5283162117894016\n",
      "-------Val acc----------\n",
      "0.9994853319608852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 510/510 [00:19<00:00, 26.36it/s]\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "       \n",
    "#----------------模型训练----------------\n",
    "       \n",
    "# 模型训练一个epoch的函数\n",
    "def train(train_loader, model, criterion, optimizer):   \n",
    "    model.train()    \n",
    "    train_loss = 0.0    \n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):        \n",
    "        input = input.to(device)        \n",
    "        target = target.to(device)        \n",
    "        output = model(input)        \n",
    "        loss = criterion(output, target)        \n",
    "        optimizer.zero_grad()        \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i % 40 == 0:            \n",
    "            print(loss.item())                    \n",
    "            \n",
    "        train_loss += loss.item()        \n",
    "    \n",
    "    return train_loss/len(train_loader)\n",
    "\n",
    "# 模型验证一个epoch的函数\n",
    "def validate(val_loader, model, criterion):    \n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    counter = 0\n",
    "    with torch.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(val_loader): \n",
    "            counter += 1\n",
    "            input = input.to(device)            \n",
    "            target = target.to(device)            \n",
    "            output = model(input)            \n",
    "            # loss = criterion(output, target)\n",
    "            val_acc += (output.argmax(1) == target).sum().item()                \n",
    "            loss = criterion(output, target)\n",
    "            val_running_loss += loss.item()\n",
    "        val_loss = val_running_loss / counter\n",
    "        return val_acc / len(val_loader.dataset), val_loss    \n",
    "        \n",
    "# 模型预测函数     \n",
    "def predict(test_loader, model, criterion):    \n",
    "    model.eval()    \n",
    "    val_acc = 0.0        \n",
    "    \n",
    "    test_pred = []    \n",
    "    with torch.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(test_loader):    \n",
    "            input = input.to(device)            \n",
    "            target = target.to(device)            \n",
    "            output = model(input)            \n",
    "            test_pred.append(output.data.cpu().numpy())                \n",
    "            return np.vstack(test_pred)\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        # 此处的self.smoothing即我们的epsilon平滑参数。\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# 定义模型，使用resnet18\n",
    "print(\"Creating model----{}\".format('resnet18d'))\n",
    "model = timm.create_model('resnet18d', pretrained=True, num_classes=24)  # 通过修改模型名字更换不同模型  \n",
    "model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = LabelSmoothing(smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.0001)\n",
    "lr_scheduler = LRScheduler(optimizer)\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "val_loss_s = []\n",
    "# 模型训练\n",
    "#resnet18大概消耗显存：3.7GB，使用Gtx1060时，训练每个epoch花费大概2min\n",
    "for i in range(25):\n",
    "    print(\"------epoch{}----------\".format(i))   \n",
    "    print(\"-------Loss----------\")      \n",
    "#     train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    train_loss2 = train(train_loader, model, criterion2, optimizer)\n",
    "#     print(train_loss)\n",
    "    print(train_loss2)\n",
    "    \n",
    "    \n",
    "    print(\"-------Val acc----------\") \n",
    "#     val_acc = validate(val_loader, model, criterion)  \n",
    "    val_acc2, val_loss  = validate(val_loader, model, criterion2)   \n",
    "    val_loss_s.append(val_loss)\n",
    "    lr_scheduler(val_loss)\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "#     print(val_acc)\n",
    "    print(val_acc2)   \n",
    "    \n",
    "    \n",
    "# 模型预测\n",
    "test_loader = torch.utils.data.DataLoader(    \n",
    "    XunFeiDataset(test_df['path'].values, [0] * test_df.shape[0],            \n",
    "        A.Compose([            \n",
    "            A.RandomCrop(450, 750), \n",
    "            ])    \n",
    "            ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "model.eval()    \n",
    "val_acc = 0.0        \n",
    "\n",
    "\n",
    "test_pred = []    \n",
    "with torch.no_grad():  \n",
    "    for input, _ in tqdm(test_loader):\n",
    "        # print(img[0])\n",
    "        input = input.to(device)                      \n",
    "        output = model(input)            \n",
    "        test_pred.append(output.data.cpu().numpy())                \n",
    "\n",
    "pred = np.vstack(test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afcc3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------结果输出----------------\n",
    "pd.DataFrame(    \n",
    "    {        \n",
    "        'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "        'label': pred.argmax(1)\n",
    "        }).to_csv('result.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机擦除\n",
    "def random_erase(img,n_holes,length,rate): #输入img为PIL图片格式的图片\n",
    "    if np.random.rand(1)[0]<rate:\n",
    "        img = np.array(img)\n",
    "        h = img.shape[0] #图片的高\n",
    "        w = img.shape[1] #图片的宽\n",
    "        \n",
    "        n_holes = np.random.randint(n_holes)\n",
    "        mask = np.ones((h, w), np.float32) #32*32w*h的全1矩阵\n",
    "\n",
    "        for n in range(n_holes): #n_holes=2,length=4 选择2个区域；每个区域的边长为4\n",
    "            y = np.random.randint(h) #0~31随机选择一个数 y=4\n",
    "            x = np.random.randint(w) #0~31随机选择一个数 x=24\n",
    "\n",
    "            y1 = np.clip(y - length // 2, 0, h) #2,0,32 ->2\n",
    "            y2 = np.clip(y + length // 2, 0, h) #6,0,32 ->6\n",
    "            x1 = np.clip(x - length // 2, 0, w) #24-2,0,32 ->22\n",
    "            x2 = np.clip(x + length // 2, 0, w) #24+2,0,32 ->26\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0. #将这一小块区域去除\n",
    "        img[:,:,0] = img[:,:,0] * mask\n",
    "        img[:,:,1] = img[:,:,1] * mask\n",
    "        img[:,:,2] = img[:,:,2] * mask\n",
    "        return Image.fromarray(img)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mixup(img ,label, mixup_img, mixup_label):#输入img和mixup为IMG格式的图片，label和mixup_label为int类型\n",
    "    img = np.array(img)\n",
    "    mixup_img = np.array(mixup_img)\n",
    "    label_onehot = np.zeros(24)\n",
    "    label_onehot[label] = 1\n",
    "    mixup_label_onehot = np.zeros(24)\n",
    "    mixup_label_onehot[mixup_label] = 1\n",
    "\n",
    "    alpha = 1\n",
    "    lam = np.random.beta(alpha,alpha) #混合比例\n",
    "\n",
    "    img_new = lam*img + (1-lam)*mixup_img\n",
    "    label_new = lam*label_onehot + (1-lam)*mixup_label_onehot\n",
    "    \n",
    "    return Image.fromarray(np.uint8(img_new)), torch.to_tensor(np.float32(label_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87529383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStat(train_data):\n",
    "    '''\n",
    "    Compute mean and variance for training data\n",
    "    :param train_data: 自定义类Dataset(或ImageFolder即可)\n",
    "    :return: (mean, std)\n",
    "    '''\n",
    "    print('Compute mean and variance for training data.')\n",
    "    print(len(train_data))\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    for X, _ in train_loader:\n",
    "        for d in range(3):\n",
    "            mean[d] += X[:, d, :, :].mean().cpu().numpy()[0]\n",
    "            std[d] += X[:, d, :, :].std().cpu().numpy()[0]\n",
    "    mean = mean/len(train_data)\n",
    "    std = std/len(train_data)\n",
    "    return list(mean), list(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集读取方法\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, label, transforms=None, mode='train'):        \n",
    "        self.img_path = img_path        \n",
    "        self.label = label   \n",
    "        self.transforms = transforms \n",
    "        self.mode = mode           \n",
    "    def __getitem__(self, index):        \n",
    "        img = Image.open(self.img_path[index]).convert('RGB') \n",
    "\n",
    "        #将label转化为one_hot编码\n",
    "        label_onehot = np.zeros(24)\n",
    "        label_onehot[self.label[index]] = 1\n",
    "        label_onehot = torch.to_tensor(np.float32(label_onehot))   \n",
    "\n",
    "        if self.mode == 'train': #训练时才做数据增强\n",
    "            #随机擦除 100代表100个正方形，10代表每个正方形边长为10,0.2代表20%的概率\n",
    "            img = random_erase(img,100,10,0.2) \n",
    "            #mixup,0.2的概率\n",
    "            if np.random.rand(1)[0]<0.2:\n",
    "                mixup_idx = np.random.randint(0, len(self.img_path)-1)\n",
    "                mixup_img = Image.open(self.img_path[mixup_idx]).convert('RGB')\n",
    "                mixup_label = self.label[mixup_idx]\n",
    "                img, label_onehot = random_mixup(img, self.label[index], mixup_img, mixup_label)\n",
    "            #cutmix,0.2的概率\n",
    "            if np.random.rand(1)[0]<0.2:\n",
    "                cutmix_idx = np.random.randint(0, len(self.img_path)-1)\n",
    "                cutmix_img = Image.open(self.img_path[cutmix_idx]).convert('RGB')\n",
    "                cutmix_label = self.label[cutmix_idx]\n",
    "                img, label_onehot = cutmix(img, self.label[index], cutmix_img, cutmix_label)\n",
    "\n",
    "        if self.transforms is not None:           \n",
    "            img = self.transforms(img)   \n",
    "\n",
    "        label_onehot = nn.functional.label_smooth(label_onehot)    \n",
    "        return img, label_onehot    \n",
    "    \n",
    "    def __len__(self):        \n",
    "        return len(self.img_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
